{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "os.remove('./debug.log')\n",
    "logger = logging.getLogger('debug')\n",
    "hdlr = logging.FileHandler('./debug.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/datasets/dsc180a-wi20-public/Malware/group_data/group_01/pipeline_output'\n",
    "A = sparse.load_npz(os.path.join(path, 'A_reduced_tr.npz'))\n",
    "B_tr = sparse.load_npz(os.path.join(path, 'B_reduced_tr.npz')).tocsr()\n",
    "P_tr = sparse.load_npz(os.path.join(path, 'P_reduced_tr.npz')).tocsr()\n",
    "A_csr = A\n",
    "A_csc = A.tocsc(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1335x1000 sparse matrix of type '<class 'numpy.uint32'>'\n",
       "\twith 238038 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1335x1 sparse matrix of type '<class 'numpy.uint32'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:, 951]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import m2v\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = m2v.Metapath2Vec(A, B_tr, P_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app_65', 'api_49', 'api_144', 'app_534']\n",
      "['app_65', 'api_151', 'api_72', 'app_703']\n",
      "['app_65', 'api_121', 'api_507', 'app_298']\n",
      "['app_65', 'api_140', 'api_177', 'app_1063']\n",
      "['app_65', 'api_158', 'api_258', 'app_154']\n",
      "['app_65', 'api_104', 'api_158', 'app_37']\n",
      "['app_65', 'api_22', 'api_59', 'app_212']\n",
      "['app_65', 'api_79', 'api_590', 'app_773']\n",
      "['app_65', 'api_126', 'api_62', 'app_1010']\n",
      "['app_65', 'api_189', 'api_400', 'app_655']\n",
      "CPU times: user 9.18 ms, sys: 6.26 ms, total: 15.4 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test one iteration of metapath2vec\n",
    "# os.remove('./debug.log')\n",
    "logger = logging.getLogger('debug')\n",
    "hdlr = logging.FileHandler('./debug.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for i in range(10):\n",
    "    metapaths = list('ABA')\n",
    "    print(model.metapath2vec(metapaths, 65))\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isinstance(model.metapath2vec(metapaths, 65), collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metas = ('AA','ABA', 'APA', 'ABPBA','APBPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta in metas:\n",
    "    print(meta)\n",
    "    model.create_corpus(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 4s, sys: 22.4 s, total: 24min 27s\n",
      "Wall time: 24min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.create_corpus('ABPBPBBPA', '_tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 12s, sys: 24.4 s, total: 26min 36s\n",
      "Wall time: 26min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.create_corpus('ABPBPBBPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tst_file(CORPUS_TEST):\n",
    "    f = open(CORPUS_TEST).readlines()\n",
    "    app_num = int(f[0].split()[0].split('_')[1])\n",
    "    if(app_num <A.shape[0]):\n",
    "        print('changing')\n",
    "        walks = []\n",
    "        for line in f:\n",
    "            walk = line.strip().split(' ')\n",
    "            walks.append([\n",
    "                f\"app_{int(node.split('_')[-1]) + 1335}\"\n",
    "                if node.startswith('app') else node\n",
    "                for node in walk\n",
    "            ])\n",
    "\n",
    "\n",
    "        f = open(CORPUS_TEST, \"w\")\n",
    "        for walk in walks:\n",
    "            f.write(' '.join(walk) + '\\n')\n",
    "        f.close()\n",
    "    else:\n",
    "        print('changed')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(metapath):\n",
    "    fp = '/datasets/dsc180a-wi20-public/Malware/group_data/group_01/metapath_corpus'\n",
    "    CORPUS = os.path.join(fp, 'meta_%s.cor'%metapath)\n",
    "    CORPUS_TEST = os.path.join(fp, 'meta_%s_tst.cor'%metapath)\n",
    "#     print(CORPUS, CORPUS_TEST)\n",
    "    check_tst_file(CORPUS_TEST)\n",
    "    \n",
    "    \n",
    "    from gensim import utils\n",
    "    import gensim.models\n",
    "\n",
    "    class MyCorpus(object):\n",
    "        \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "        def __init__(self, CORPUS, CORPUS_TEST):\n",
    "            self.lines = open(CORPUS).readlines()\n",
    "    #         print(len(self.lines))\n",
    "            self.lines += open(CORPUS_TEST).readlines()  # !!! Test\n",
    "    #         print(len(self.lines))\n",
    "\n",
    "        def __iter__(self):\n",
    "            corpus_path = CORPUS\n",
    "            for line in tqdm(self.lines):\n",
    "                # assume there's one document per line, tokens separated by whitespace\n",
    "                yield line.strip().split(' ')\n",
    "    sentences = MyCorpus(CORPUS, CORPUS_TEST)\n",
    "    model = gensim.models.Word2Vec(sentences=sentences, min_count=1, size=200, window=2)\n",
    "    \n",
    "    meta_tr = pd.read_csv(os.path.join(path, 'meta_tr.csv'), index_col=0)\n",
    "    meta_tst = pd.read_csv(os.path.join(path, 'meta_tst.csv'), index_col=0)\n",
    "\n",
    "    y_train = meta_tr.label == 'class1'\n",
    "    y_test = meta_tst.label == 'class1'\n",
    "\n",
    "    app_vec = np.array([model.wv[f'app_{i}'] for i in range(len(meta_tr))])\n",
    "    app_vec_tst = np.array([model.wv[f'app_{i}'] for i in range(len(meta_tr), len(meta_tr) + len(meta_tst))])\n",
    "    \n",
    "    print('training')\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', C=10, gamma=0.1)\n",
    "    svm.fit(app_vec, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(app_vec_tst)\n",
    "    print('train_acc: ', svm.score(app_vec, y_train), '\\n')\n",
    "    print('test_acc: ', svm.score(app_vec_tst, y_test), '\\n')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2670000/2670000 [00:06<00:00, 406782.27it/s]\n",
      "100%|██████████| 2670000/2670000 [00:38<00:00, 69894.43it/s]\n",
      "100%|██████████| 2670000/2670000 [00:36<00:00, 72246.86it/s]\n",
      "100%|██████████| 2670000/2670000 [00:36<00:00, 72799.89it/s]\n",
      "100%|██████████| 2670000/2670000 [00:36<00:00, 73759.11it/s]\n",
      "100%|██████████| 2670000/2670000 [00:35<00:00, 74447.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "train_acc:  1.0 \n",
      "\n",
      "test_acc:  0.49812734082397003 \n",
      "\n",
      "1 670 0 664\n",
      "CPU times: user 8min, sys: 6.99 s, total: 8min 7s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction('ABPBPBBPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/datasets/dsc180a-wi20-public/Malware/group_data/group_01/pipeline_output'\n",
    "label = pd.read_csv(os.path.join(path, 'meta_tr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = []  # positions in vector space\n",
    "    labels = []  # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        if 'app' in word:\n",
    "            if (label.iloc[int(word.split('_')[1]), 1] == 'class1'):\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "            vectors.append(model.wv[word])\n",
    "            # labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, metapath, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='markers',\n",
    "                       text=labels, marker=dict(size=5, color=labels)))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title = \"Scatter graph of metapath: \" + metapath,\n",
    "#         xaxis_title=\"x Axis Title\",\n",
    "#         yaxis_title=\"y Axis Title\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=18,\n",
    "            color=\"#7f7f7f\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "#     data = [trace]\n",
    "\n",
    "#     if plot_in_notebook:\n",
    "#         init_notebook_mode(connected=True)\n",
    "#         iplot(data, filename='word-embedding-plot')\n",
    "#     else:\n",
    "#         plot(data, filename='word-embedding-plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "plot_with_plotly(x_vals, y_vals, labels, 'AA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
