{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "from tqdm import tqdm\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('../config/data-params.json'))\n",
    "\n",
    "config['master_matrix'] =  '.' + config['master_matrix']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_A = sparse.load_npz(config['master_matrix'] + '/train_A.npz').tocsr()\n",
    "train_B = sparse.load_npz(config['master_matrix'] + '/train_B.npz').tocsc()\n",
    "train_P = sparse.load_npz(config['master_matrix'] + '/train_P.npz').tocsc()\n",
    "train_A_csc = train_A.tocsc()\n",
    "\n",
    "test_A = sparse.load_npz(config['master_matrix'] + '/test_A.npz').tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_APA_T = train_A.dot(train_P).dot(train_A.T)\n",
    "test_APA_T = test_A.dot(train_P).dot(train_A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABPBA\n",
    "def generate_corpus(walk_length=5):\n",
    "    while True:\n",
    "              \n",
    "        app = np.random.choice(np.arange(train_A.shape[0]))\n",
    "        \n",
    "        path = f'app_{app}'\n",
    "        \n",
    "        for i in range(walk_length):\n",
    "        \n",
    "            api_i = np.random.choice(np.nonzero(train_A[app])[1])\n",
    "            api_bi = np.random.choice(np.nonzero(train_B[:, api_i])[0])\n",
    "            api_p = np.random.choice(np.nonzero(train_P[:, api_bi])[0])\n",
    "            api_bj = np.random.choice(np.nonzero(train_B[:, api_p])[0])\n",
    "            app = np.random.choice(np.nonzero(train_A_csc[:, api_bj])[0])\n",
    "\n",
    "            path += f' api_{api_i} api_{api_bi} api_{api_p} api_{api_bj} app_{app}'\n",
    "            \n",
    "        yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABPBA\n",
    "def generate_corpus_limit_length():\n",
    "    while True:\n",
    "        app_i = np.random.choice(np.arange(train_A.shape[0]))\n",
    "        api_i = np.random.choice(np.nonzero(train_A[app_i])[1])\n",
    "        api_bi = np.random.choice(np.nonzero(train_B[:, api_i])[0])\n",
    "        api_p = np.random.choice(np.nonzero(train_P[:, api_bi])[0])\n",
    "        api_bj = np.random.choice(np.nonzero(train_B[:, api_p])[0])\n",
    "        app_j = np.random.choice(np.nonzero(train_A_csc[:, api_bj])[0])\n",
    "\n",
    "        yield f'app_{app_i} api_{api_i} api_{api_bi} api_{api_p} api_{api_bj} app_{app_j}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_function = generate_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(corpus_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = open('test.cor', 'w')\n",
    "for _ in tqdm(range(10000)):\n",
    "    f.write(next(corpus_function) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head test.cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = './test.cor'\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield line.strip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(sentences.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('app_500', 'app_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar(positive=['app_334'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
