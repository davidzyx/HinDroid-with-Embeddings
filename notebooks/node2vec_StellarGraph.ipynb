{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p_tqdm import p_map, p_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_tr.npz   B_tr.npz  meta_tr.csv   P_tr.npz\r\n",
      "A_tst.npz  meta.csv  meta_tst.csv  test.cor\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tr = sparse.load_npz('../data/processed/A_tr.npz')\n",
    "B_tr = sparse.load_npz('../data/processed/B_tr.npz')\n",
    "P_tr = sparse.load_npz('../data/processed/P_tr.npz')\n",
    "A_tr_csr = A_tr\n",
    "A_tr_csc = A_tr.tocsc(copy=True)  # memory is cheap ;D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<656x1563400 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7570310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tr = pd.read_csv('../data/processed/meta_tr.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tr['counts'] = np.asarray(A_tr.sum(axis=1)).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0</th>\n",
       "      <td>328.0</td>\n",
       "      <td>19980.384146</td>\n",
       "      <td>11644.184581</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11712.0</td>\n",
       "      <td>19369.5</td>\n",
       "      <td>27750.75</td>\n",
       "      <td>52508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class1</th>\n",
       "      <td>328.0</td>\n",
       "      <td>3099.829268</td>\n",
       "      <td>4920.820259</td>\n",
       "      <td>87.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>4849.00</td>\n",
       "      <td>44350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count          mean           std   min      25%      50%       75%  \\\n",
       "label                                                                         \n",
       "class0  328.0  19980.384146  11644.184581  61.0  11712.0  19369.5  27750.75   \n",
       "class1  328.0   3099.829268   4920.820259  87.0    276.0    648.0   4849.00   \n",
       "\n",
       "            max  \n",
       "label            \n",
       "class0  52508.0  \n",
       "class1  44350.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_tr.groupby('label').counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<656x1563400 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7570310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1563400x1563400 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 38980208 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1563400x1563400 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 27097178 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tr_edges = []\n",
    "for i, row in tqdm(enumerate(A_tr), total=A_tr.shape[0]):\n",
    "    for j in row.indices:\n",
    "        A_tr_edges.append([f'app_{i}', f'api_{j}'])\n",
    "\n",
    "df_A = pd.DataFrame(A_tr_edges, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_tr_edges = []\n",
    "for i, row in tqdm(enumerate(B_tr), total=B_tr.shape[1]):\n",
    "    for j in row.indices:\n",
    "        B_tr_edges.append([f'api_{i}', f'api_{j}'])\n",
    "\n",
    "df_B = pd.DataFrame(B_tr_edges, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_tr_edges = []\n",
    "for i, row in tqdm(enumerate(P_tr), total=P_tr.shape[1]):\n",
    "    for j in row.indices:\n",
    "        P_tr_edges.append([f'api_{i}', f'api_{j}'])\n",
    "\n",
    "df_P = pd.DataFrame(P_tr_edges, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del A_tr_edges\n",
    "del B_tr_edges\n",
    "del P_tr_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.index = np.arange(df_A.shape[0], df_A.shape[0] + df_B.shape[0])\n",
    "df_P.index = np.arange(df_A.shape[0] + df_B.shape[0], df_A.shape[0] + df_B.shape[0] + df_P.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73647695"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_nodes = pd.DataFrame([], index=[f'app_{i}' for i in range(A_tr.shape[0])])\n",
    "api_nodes = pd.DataFrame([], index=[f'api_{i}' for i in range(B_tr.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 23.6 s, total: 3min 53s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph = StellarGraph(\n",
    "    nodes={'APP': app_nodes, 'API': api_nodes},\n",
    "    edges={'A': df_A, 'B': df_B, 'P': df_P},\n",
    "    is_directed=False,\n",
    "    dtype='int8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 1564056, Edges: 73647696\n",
      "\n",
      " Node types:\n",
      "  API: [1563400]\n",
      "    Features: none\n",
      "    Edge types: API-A->APP, API-B->API, API-P->API\n",
      "  APP: [656]\n",
      "    Features: none\n",
      "    Edge types: APP-A->API\n",
      "\n",
      " Edge types:\n",
      "    API-B->API: [38980208]\n",
      "    API-P->API: [27097178]\n",
      "    APP-A->API: [7570310]\n"
     ]
    }
   ],
   "source": [
    "print(graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d4e17d07014a288bd97b941183793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1564056.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-6a62ecf6c765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# number of random walks per root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Defines (unormalised) probability, 1/p, of returning to source node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Defines (unormalised) probability, 1/q, for moving away from source node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of random walks: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-01d70e010e54>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nodes, n, length, p, q, seed, weighted)\u001b[0m\n\u001b[1;32m    262\u001b[0m                             (\n\u001b[1;32m    263\u001b[0m                                 \u001b[0mtransition_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                                 \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m                             ),\n\u001b[1;32m    266\u001b[0m                         )\n",
      "\u001b[0;32m<ipython-input-99-01d70e010e54>\u001b[0m in \u001b[0;36mnaive_weighted_choices\u001b[0;34m(rs, weights)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msubinterval_ends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mrunning_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detected negative weight: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-01d70e010e54>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m                             (\n\u001b[1;32m    263\u001b[0m                                 \u001b[0mtransition_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                                 \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m                             ),\n\u001b[1;32m    266\u001b[0m                         )\n",
      "\u001b[0;32m<ipython-input-99-01d70e010e54>\u001b[0m in \u001b[0;36mtransition_probability\u001b[0;34m(nn, current_node, weighted)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprevious_node\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# d_tx = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_cn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                     \u001b[0;32melif\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprevious_node_neighbours\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# d_tx = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_cn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# d_tx = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "walks = rw.run(\n",
    "    nodes=list(graph.nodes()),  # root nodes\n",
    "    length=100,  # maximum length of a random walk\n",
    "    n=2,  # number of random walks per root node\n",
    "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    ")\n",
    "print(\"Number of random walks: {}\".format(len(walks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from collections import defaultdict, deque\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "\n",
    "from stellargraph import GraphSchema\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.core.utils import is_real_iterable\n",
    "from stellargraph.core.experimental import experimental\n",
    "from stellargraph.random import random_state\n",
    "\n",
    "\n",
    "class GraphWalk(object):\n",
    "    \"\"\"\n",
    "    Base class for exploring graphs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, graph_schema=None, seed=None):\n",
    "        self.graph = graph\n",
    "\n",
    "        # Initialize the random state\n",
    "        self._check_seed(seed)\n",
    "\n",
    "        self._random_state, self._np_random_state = random_state(seed)\n",
    "\n",
    "        # We require a StellarGraph for this\n",
    "        if not isinstance(graph, StellarGraph):\n",
    "            raise TypeError(\"Graph must be a StellarGraph or StellarDiGraph.\")\n",
    "\n",
    "        if not graph_schema:\n",
    "            self.graph_schema = self.graph.create_graph_schema()\n",
    "        else:\n",
    "            self.graph_schema = graph_schema\n",
    "\n",
    "        if type(self.graph_schema) is not GraphSchema:\n",
    "            self._raise_error(\n",
    "                \"The parameter graph_schema should be either None or of type GraphSchema.\"\n",
    "            )\n",
    "\n",
    "    def get_adjacency_types(self):\n",
    "        # Allow additional info for heterogeneous graphs.\n",
    "        adj = getattr(self, \"adj_types\", None)\n",
    "        if not adj:\n",
    "            # Create a dict of adjacency lists per edge type, for faster neighbour sampling from graph in SampledHeteroBFS:\n",
    "            self.adj_types = adj = self.graph._adjacency_types(self.graph_schema)\n",
    "        return adj\n",
    "\n",
    "    def _check_seed(self, seed):\n",
    "        if seed is not None:\n",
    "            if type(seed) != int:\n",
    "                self._raise_error(\n",
    "                    \"The random number generator seed value, seed, should be integer type or None.\"\n",
    "                )\n",
    "            if seed < 0:\n",
    "                self._raise_error(\n",
    "                    \"The random number generator seed value, seed, should be non-negative integer or None.\"\n",
    "                )\n",
    "\n",
    "    def _get_random_state(self, seed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seed: The optional seed value for a given run.\n",
    "\n",
    "        Returns:\n",
    "            The random state as determined by the seed.\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            # Restore the random state\n",
    "            return self._random_state\n",
    "        # seed the random number generator\n",
    "        rs, _ = random_state(seed)\n",
    "        return rs\n",
    "\n",
    "    def neighbors(self, node):\n",
    "        if not self.graph.has_node(node):\n",
    "            self._raise_error(\"node {} not in graph\".format(node))\n",
    "        return self.graph.neighbors(node)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        To be overridden by subclasses. It is the main entry point for performing random walks on the given\n",
    "        graph.\n",
    "\n",
    "        It should return the sequences of nodes in each random walk.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _raise_error(self, msg):\n",
    "        raise ValueError(\"({}) {}\".format(type(self).__name__, msg))\n",
    "\n",
    "    def _check_common_parameters(self, nodes, n, length, seed):\n",
    "        \"\"\"\n",
    "        Checks that the parameter values are valid or raises ValueError exceptions with a message indicating the\n",
    "        parameter (the first one encountered in the checks) with invalid value.\n",
    "\n",
    "        Args:\n",
    "            nodes: <list> A list of root node ids from which to commence the random walks.\n",
    "            n: <int> Number of walks per node id.\n",
    "            length: <int> Maximum length of each walk.\n",
    "            seed: <int> Random number generator seed.\n",
    "        \"\"\"\n",
    "        self._check_nodes(nodes)\n",
    "        self._check_repetitions(n)\n",
    "        self._check_length(length)\n",
    "        self._check_seed(seed)\n",
    "\n",
    "    def _check_nodes(self, nodes):\n",
    "        if nodes is None:\n",
    "            self._raise_error(\"A list of root node IDs was not provided.\")\n",
    "        if not is_real_iterable(nodes):\n",
    "            self._raise_error(\"Nodes parameter should be an iterable of node IDs.\")\n",
    "        if (\n",
    "            len(nodes) == 0\n",
    "        ):  # this is not an error but maybe a warning should be printed to inform the caller\n",
    "            warnings.warn(\n",
    "                \"No root node IDs given. An empty list will be returned as a result.\",\n",
    "                RuntimeWarning,\n",
    "                stacklevel=3,\n",
    "            )\n",
    "\n",
    "    def _check_repetitions(self, n):\n",
    "        if type(n) != int:\n",
    "            self._raise_error(\n",
    "                \"The number of walks per root node, n, should be integer type.\"\n",
    "            )\n",
    "        if n <= 0:\n",
    "            self._raise_error(\n",
    "                \"The number of walks per root node, n, should be a positive integer.\"\n",
    "            )\n",
    "\n",
    "    def _check_length(self, length):\n",
    "        if type(length) != int:\n",
    "            self._raise_error(\"The walk length, length, should be integer type.\")\n",
    "        if length <= 0:\n",
    "            # Technically, length 0 should be okay, but by consensus is invalid.\n",
    "            self._raise_error(\"The walk length, length, should be a positive integer.\")\n",
    "\n",
    "    # For neighbourhood sampling\n",
    "    def _check_sizes(self, n_size):\n",
    "        err_msg = \"The neighbourhood size must be a list of non-negative integers.\"\n",
    "        if not isinstance(n_size, list):\n",
    "            self._raise_error(err_msg)\n",
    "        if len(n_size) == 0:\n",
    "            # Technically, length 0 should be okay, but by consensus it is invalid.\n",
    "            self._raise_error(\"The neighbourhood size list should not be empty.\")\n",
    "        for d in n_size:\n",
    "            if type(d) != int or d < 0:\n",
    "                self._raise_error(err_msg)\n",
    "\n",
    "                \n",
    "class BiasedRandomWalk(GraphWalk):\n",
    "    \"\"\"\n",
    "    Performs biased second order random walks (like those used in Node2Vec algorithm\n",
    "    https://snap.stanford.edu/node2vec/) controlled by the values of two parameters p and q.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, nodes, n, length, p=1.0, q=1.0, seed=None, weighted=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Perform a random walk starting from the root nodes.\n",
    "\n",
    "        Args:\n",
    "            nodes (list): The root nodes as a list of node IDs\n",
    "            n (int): Total number of random walks per root node\n",
    "            length (int): Maximum length of each random walk\n",
    "            p (float, default 1.0): Defines probability, 1/p, of returning to source node\n",
    "            q (float, default 1.0): Defines probability, 1/q, for moving to a node away from the source node\n",
    "            seed (int, optional): Random number generator seed; default is None\n",
    "            weighted (bool, default False): Indicates whether the walk is unweighted or weighted\n",
    "\n",
    "        Returns:\n",
    "            List of lists of nodes ids for each of the random walks\n",
    "\n",
    "        \"\"\"\n",
    "        self._check_common_parameters(nodes, n, length, seed)\n",
    "        self._check_weights(p, q, weighted)\n",
    "        rs = self._get_random_state(seed)\n",
    "\n",
    "        if weighted:\n",
    "            # Check that all edge weights are greater than or equal to 0.\n",
    "            # Also, if the given graph is a MultiGraph, then check that there are no two edges between\n",
    "            # the same two nodes with different weights.\n",
    "            for node in self.graph.nodes():\n",
    "                # TODO Encapsulate edge weights\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "\n",
    "                    wts = set()\n",
    "                    for weight in self.graph._edge_weights(node, neighbor):\n",
    "                        if weight is None or np.isnan(weight) or weight == np.inf:\n",
    "                            self._raise_error(\n",
    "                                \"Missing or invalid edge weight ({}) between ({}) and ({}).\".format(\n",
    "                                    weight, node, neighbor\n",
    "                                )\n",
    "                            )\n",
    "                        if not isinstance(weight, (int, float)):\n",
    "                            self._raise_error(\n",
    "                                \"Edge weight between nodes ({}) and ({}) is not numeric ({}).\".format(\n",
    "                                    node, neighbor, weight\n",
    "                                )\n",
    "                            )\n",
    "                        if weight < 0:  # check if edge has a negative weight\n",
    "                            self._raise_error(\n",
    "                                \"An edge weight between nodes ({}) and ({}) is negative ({}).\".format(\n",
    "                                    node, neighbor, weight\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                        wts.add(weight)\n",
    "                    if len(wts) > 1:\n",
    "                        # multigraph with different weights on edges between same pair of nodes\n",
    "                        self._raise_error(\n",
    "                            \"({}) and ({}) have multiple edges with weights ({}). Ambiguous to choose an edge for the random walk.\".format(\n",
    "                                node, neighbor, list(wts)\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "        ip = 1.0 / p\n",
    "        iq = 1.0 / q\n",
    "\n",
    "        walks = []\n",
    "        for node in tqdm(nodes):  # iterate over root nodes\n",
    "            for walk_number in range(n):  # generate n walks per root node\n",
    "                # the walk starts at the root\n",
    "                walk = [node]\n",
    "\n",
    "                neighbours = self.neighbors(node)\n",
    "\n",
    "                previous_node = node\n",
    "                previous_node_neighbours = neighbours\n",
    "\n",
    "                # calculate the appropriate unnormalised transition\n",
    "                # probability, given the history of the walk\n",
    "                def transition_probability(nn, current_node, weighted):\n",
    "\n",
    "                    if weighted:\n",
    "                        # TODO Encapsulate edge weights\n",
    "                        weight_cn = self.graph._edge_weights(current_node, nn)[0]\n",
    "                    else:\n",
    "                        weight_cn = 1.0\n",
    "\n",
    "                    if nn == previous_node:  # d_tx = 0\n",
    "                        return ip * weight_cn\n",
    "                    elif nn in previous_node_neighbours:  # d_tx = 1\n",
    "                        return 1.0 * weight_cn\n",
    "                    else:  # d_tx = 2\n",
    "                        return iq * weight_cn\n",
    "\n",
    "                if neighbours:\n",
    "                    current_node = rs.choice(neighbours)\n",
    "                    for _ in range(length - 1):\n",
    "                        walk.append(current_node)\n",
    "                        neighbours = self.neighbors(current_node)\n",
    "\n",
    "                        if not neighbours:\n",
    "                            break\n",
    "\n",
    "                        # select one of the neighbours using the\n",
    "                        # appropriate transition probabilities\n",
    "                        choice = naive_weighted_choices(\n",
    "                            rs,\n",
    "                            (\n",
    "                                transition_probability(nn, current_node, weighted)\n",
    "                                for nn in neighbours\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "                        previous_node = current_node\n",
    "                        previous_node_neighbours = neighbours\n",
    "                        current_node = neighbours[choice]\n",
    "\n",
    "                walks.append(walk)\n",
    "\n",
    "        return walks\n",
    "\n",
    "\n",
    "    def _check_weights(self, p, q, weighted):\n",
    "        \"\"\"\n",
    "        Checks that the parameter values are valid or raises ValueError exceptions with a message indicating the\n",
    "        parameter (the first one encountered in the checks) with invalid value.\n",
    "\n",
    "        Args:\n",
    "            p: <float> The backward walk 'penalty' factor.\n",
    "            q: <float> The forward walk 'penalty' factor.\n",
    "            weighted: <False or True> Indicates whether the walk is unweighted or weighted.\n",
    "       \"\"\"\n",
    "        if p <= 0.0:\n",
    "            self._raise_error(\"Parameter p should be greater than 0.\")\n",
    "\n",
    "        if q <= 0.0:\n",
    "            self._raise_error(\"Parameter q should be greater than 0.\")\n",
    "\n",
    "        if type(weighted) != bool:\n",
    "            self._raise_error(\n",
    "                \"Parameter weighted has to be either False (unweighted random walks) or True (weighted random walks).\"\n",
    "            )\n",
    "\n",
    "def naive_weighted_choices(rs, weights):\n",
    "    \"\"\"\n",
    "    Select an index at random, weighted by the iterator `weights` of\n",
    "    arbitrary (non-negative) floats. That is, `x` will be returned\n",
    "    with probability `weights[x]/sum(weights)`.\n",
    "\n",
    "    For doing a single sample with arbitrary weights, this is much (5x\n",
    "    or more) faster than numpy.random.choice, because the latter\n",
    "    requires a lot of preprocessing (normalized probabilties), and\n",
    "    does a lot of conversions/checks/preprocessing internally.\n",
    "    \"\"\"\n",
    "\n",
    "    # divide the interval [0, sum(weights)) into len(weights)\n",
    "    # subintervals [x_i, x_{i+1}), where the width x_{i+1} - x_i ==\n",
    "    # weights[i]\n",
    "    subinterval_ends = []\n",
    "    running_total = 0\n",
    "    for w in weights:\n",
    "        if w < 0:\n",
    "            raise ValueError(\"Detected negative weight: {}\".format(w))\n",
    "        running_total += w\n",
    "        subinterval_ends.append(running_total)\n",
    "\n",
    "    # pick a place in the overall interval\n",
    "    x = rs.random() * running_total\n",
    "\n",
    "    # find the subinterval that contains the place, by looking for the\n",
    "    # first subinterval where the end is (strictly) after it\n",
    "    for idx, end in enumerate(subinterval_ends):\n",
    "        if x < end:\n",
    "            break\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample paths strictly using node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import n2v\n",
    "# del n2v\n",
    "n2v = n2v.Node2Vec(A_tr, B_tr, P_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v.perform_one_walk_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v.perform_one_walk_metapath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = n2v.save_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l node2vec_n=1_p=2_q=1_wl=100.cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = 'node2vec_n=1_p=2_q=1_wl=100.cor'\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield line.strip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, min_count=1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls HinDroid-with-Embeddings/data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tr = pd.read_csv('HinDroid-with-Embeddings/data/processed/meta_tr.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = meta_tr.label == 'class1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_vec = np.array([model.wv[f'app_{i}'] for i in range(len(meta_tr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(app_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(app_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        if 'api' in word: continue\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(n_components=2)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 12)) \n",
    "    for i in range(len(x)):\n",
    "        color = 'b' if meta_tr.label.iloc[i] == 'class1' else 'r'\n",
    "        plt.scatter(x[i],y[i],c=color)\n",
    "#         plt.annotate(labels[i],\n",
    "#                      xy=(x[i], y[i]),\n",
    "#                      xytext=(5, 2),\n",
    "#                      textcoords='offset points',\n",
    "#                      ha='right',\n",
    "#                      va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
